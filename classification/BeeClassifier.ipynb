{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classifier for Bee Wing Identification\n",
    "\n",
    "Reads in csv file with list of features as well as labeled class,\n",
    "and uses a specified Classifer to train and test the data. Can save model.\n",
    "\n",
    "'''\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score, ShuffleSplit\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class BeeClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_ratio = 0.8\n",
    "        self.model = None\n",
    "    \n",
    "    def set_train_ratio(self, ratio):\n",
    "        self.train_ratio = ratio\n",
    "        \n",
    "    def get_classes(self, data):\n",
    "        bee_data = pd.read_csv(data)\n",
    "        factorized = pd.factorize(bee_data['species'])\n",
    "        return factorized[1]\n",
    "    \n",
    "    def train(self, data, classifier='random forest', train_ratio=0.8, display_accuracy = True, save=True, num_species = 7):\n",
    "        '''Classifies the species of bees given a set of data.\n",
    "        \n",
    "           data: a csv file containing data and labels\n",
    "           classifier: the classifier used to train the model\n",
    "               options: ['random forest'(default), 'svm', 'k-nearest']\n",
    "           train_ratio: the amount of data split used to train the model\n",
    "           display_accuracy: displays the accuracy of the model in confusion matrix\n",
    "           save: saves the model\n",
    "        '''\n",
    "        #Loads in data, separates out species labels\n",
    "        bee_data = pd.read_csv(data)\n",
    "        labels = bee_data['species']\n",
    "\n",
    "        #Splits up the bee_data into training and test set, factorizes it into numbers, instead of species\n",
    "        bee_data['is_train'] = np.random.uniform(0, 1, len(bee_data)) <= train_ratio\n",
    "        train_data, test_data = bee_data[bee_data['is_train']==True], bee_data[bee_data['is_train']==False]\n",
    "        features = bee_data.columns[:3]\n",
    "        print(features)\n",
    "        self.train_data, self.test_data, features= train_data, test_data, features\n",
    "        factorized = pd.factorize(train_data['species'])\n",
    "        training_labels, testing_labels, classes = factorized[0], pd.factorize(test_data['species'])[0], factorized[1]\n",
    "        self.classes = classes\n",
    "        train, test = train_data[features], test_data[features]\n",
    "        \n",
    "        print(\"Classes \" + classes)\n",
    "\n",
    "        #Creates a Classifier, fits it on training data, and predicts on test data\n",
    "        if classifier=='k-nearest':\n",
    "            clf = KNeighborsClassifier(7)\n",
    "        elif classifier=='svm':\n",
    "            clf = SVC()\n",
    "        else:\n",
    "            clf = RandomForestClassifier(random_state=42)\n",
    "            \n",
    "        clf.fit(train, training_labels)\n",
    "        predictions = clf.predict(test)\n",
    "        \n",
    "        #Saves model as part of BeeClassifier object\n",
    "        if save:\n",
    "            self.model = clf\n",
    "            \n",
    "        #Displays the accuracy of the model using test.\n",
    "        if display_accuracy and train_ratio < 1:\n",
    "            self.test()\n",
    "            \n",
    "    \n",
    "    def test(self, data=None, classes=None):\n",
    "        if data is not None:\n",
    "            self.test_data = data\n",
    "        if classes is not None:\n",
    "            self.classes = classes\n",
    "        if self.model is not None and self.classes is not None:\n",
    "            clf = self.model\n",
    "            features = self.test_data.columns[:3]\n",
    "            test = self.test_data[features]\n",
    "\n",
    "            predictions = clf.predict(test)\n",
    "            factorized = pd.factorize(self.test_data['species'])\n",
    "            training_labels, testing_labels = factorized[0], pd.factorize(self.test_data['species'])[0]\n",
    "            \n",
    "            #Calculates accuracy of the prediction on the test data\n",
    "            accuracyCLF = accuracy_score(testing_labels, predictions)\n",
    "            print(\"Classifier Accuracy: \", accuracyCLF)\n",
    "\n",
    "            #Displays a confusion of classified species\n",
    "            print(\"\\nConfusion Matrix: \")\n",
    "            print(predictions)\n",
    "            print(self.classes)\n",
    "            preds = self.classes[predictions]\n",
    "            testing_labs = self.classes[testing_labels]\n",
    "            confusion_mat = pd.crosstab(testing_labs, preds, rownames = ['Actual Species'], colnames = ['Predicted Species'])\n",
    "            print(confusion_mat, \"\\n\\n\")\n",
    "        else:\n",
    "            print(\"No model to test. Please train a model using train \")\n",
    "        \n",
    "    \n",
    "    def cross_validate(self, data, classifier='random forest'):\n",
    "        #Cross Validation\n",
    "        print(\"Performing Cross Validation...\")\n",
    "        bee_data = pd.read_csv(data)\n",
    "        target = bee_data['species']\n",
    "        data = bee_data[bee_data.columns[:3]]\n",
    "        \n",
    "        #Splits training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=0)\n",
    "        \n",
    "        #Chooses a classifier\n",
    "        if classifier=='k-nearest':\n",
    "            clf = KNeighborsClassifier(7)\n",
    "        elif classifier=='svm':\n",
    "            clf = SVC()\n",
    "        else:\n",
    "            clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        scores = cross_val_score(clf, data, target, cv = 4)\n",
    "        print(\"Cross Validation Scores (Test Size 0.25): \", scores)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "        cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "        scores2 = cross_val_score(clf, data, target, cv=cv)\n",
    "        print(\"Cross Validation Scores (Shuffled, Test Size 0.3)\", cross_val_score(clf, data, target, cv=cv))\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))\n",
    "    \n",
    "    def save_model(self, file_name=\"model.pkl\"):\n",
    "        '''\n",
    "        Saves model in saved_models folder.\n",
    "        '''\n",
    "        if self.model:\n",
    "            joblib.dump(clf, \"saved_models/\" + file_name) \n",
    "            print(\"Model saved successfully!\")\n",
    "        else:\n",
    "            print(\"No model to save. Run train first.\")\n",
    "            \n",
    "    def load_model(self, classes, file_name=\"model.pkl\"):\n",
    "        '''\n",
    "        Loads model from saved_models folder, saves it in object.\n",
    "        '''\n",
    "        try:\n",
    "            self.model = joblib.load('saved_models/'+file_name)\n",
    "            print(self.model)\n",
    "        except:\n",
    "            print(\"Unable to find file named \" + file_name)\n",
    "    \n",
    "    def find_best_rf_model(self, data, train_ratio=0.8, param_grid=None):\n",
    "        #Loads in data, separates out species labels\n",
    "        bee_data = pd.read_csv(data)\n",
    "        labels = bee_data['species']\n",
    "\n",
    "        #Splits up the bee_data into training and test set, factorizes it into numbers, instead of species\n",
    "        bee_data['is_train'] = np.random.uniform(0, 1, len(bee_data)) <= train_ratio\n",
    "        train_data, test_data = bee_data[bee_data['is_train']==True], bee_data[bee_data['is_train']==False]\n",
    "        features = bee_data.columns[:3]\n",
    "        factorized = pd.factorize(train_data['species'])\n",
    "        training_labels, testing_labels, classes = factorized[0], pd.factorize(test_data['species'])[0], factorized[1]\n",
    "        train, test = train_data[features], test_data[features]\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=42)\n",
    "        if param_grid is None:\n",
    "            param_grid = {\n",
    "                'n_estimators': [5, 10, 15, 20, 25, 30],\n",
    "                'max_depth': [2, 5, 7, 9, 11, 15],\n",
    "                'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
    "                #'min_impurity_decrease': [0, 0.1]\n",
    "            }\n",
    "\n",
    "        clf = GridSearchCV(rf, param_grid)\n",
    "        clf.fit(train, training_labels)\n",
    "\n",
    "        print(\"Accuracy:\", clf.best_score_)\n",
    "        print(clf.best_estimator_)\n",
    "        \n",
    "        best_model.fit(train, training_labels)\n",
    "        predictions = best_model.predict(test)\n",
    "\n",
    "        accuracyCLF = accuracy_score(testing_labels, predictions)\n",
    "        print(accuracyCLF)\n",
    "        return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = BeeClassifier()\n",
    "# clf.train(\"bee_info.csv\", classifier='k-nearest', display_accuracy = True)\n",
    "# clf.cross_validate(\"bee_info.csv\", classifier='k-nearest')\n",
    "# clf.save_model()\n",
    "# data = clf.test_data\n",
    "\n",
    "# classes = clf.get_classes(\"bee_info.csv\")\n",
    "# clf.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf2 = BeeClassifier()\n",
    "# # print(data)\n",
    "# clf2.load_model(classes=classes)\n",
    "# #print(clf2.model)\n",
    "# clf2.test(data, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = BeeClassifier()\n",
    "# clf.train(\"bee_wing_features.csv\", classifier='random forest', display_accuracy=True)\n",
    "# # clf.cross_validate(\"bee_wing_features.csv\", classifier='random forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.684824902724\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "0.0718562874251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BeeClassifier()\n",
    "clf.find_best_rf_model(\"bee_wing_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#             max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
    "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#             min_samples_leaf=1, min_samples_split=2,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
    "#             oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "# best_model.fit(train, training_labels)\n",
    "# predictions = best_model.predict(test)\n",
    "\n",
    "# accuracyCLF = accuracy_score(testing_labels, predictions)\n",
    "# print(accuracyCLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Loads in data, separates out species labels\n",
    "bee_data = pd.read_csv(\"bee_wing_features.csv\")\n",
    "labels = bee_data['species']\n",
    "train_ratio = 0.8\n",
    "\n",
    "#Splits up the bee_data into training and test set, factorizes it into numbers, instead of species\n",
    "bee_data['is_train'] = np.random.uniform(0, 1, len(bee_data)) <= train_ratio\n",
    "train_data, test_data = bee_data[bee_data['is_train']==True], bee_data[bee_data['is_train']==False]\n",
    "features = bee_data.columns[:3]\n",
    "factorized = pd.factorize(train_data['species'])\n",
    "training_labels, testing_labels, classes = factorized[0], pd.factorize(test_data['species'])[0], factorized[1]\n",
    "train, test = train_data[features], test_data[features]\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15, 20, 25, 30],\n",
    "    'max_depth': [2, 5, 7, 9, 11, 15],\n",
    "    'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
    "    #'min_impurity_decrease': [0, 0.1]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(rf, param_grid)\n",
    "clf.fit(train, training_labels)\n",
    "\n",
    "print(\"Accuracy:\", clf.best_score_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "best_model.fit(train, training_labels)\n",
    "predictions = best_model.predict(test)\n",
    "\n",
    "accuracyCLF = accuracy_score(testing_labels, predictions)\n",
    "print(accuracyCLF)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
